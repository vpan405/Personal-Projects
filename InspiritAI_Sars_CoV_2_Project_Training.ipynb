{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_df.drop('label', 1)\n",
    "Y = balanced_df.label\n",
    "data = \"X (features)\" #@param ['X (features)', 'Y (label)']\n",
    "start = 1 #@param {type:'integer'}\n",
    "stop =  10#@param {type:'integer'}\n",
    "\n",
    "if start>=stop:print(\"Start must be < stop!\")\n",
    "else:\n",
    "  if data=='X (features)':\n",
    "    print(X.iloc[start:stop])\n",
    "  if data=='Y (label)':\n",
    "    print(Y[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
    "\n",
    "# Split into training/testing set. Use a training size of .8\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=1)\n",
    "\n",
    "# Train/fit model\n",
    "lm.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set.\n",
    "Y_pred = lm.predict(X_test)\n",
    "\n",
    "# Compute accuracy.\n",
    "accuracy = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy: %\", accuracy)\n",
    "\n",
    "# Compute confusion matrix.\n",
    "confusion_mat = pd.DataFrame(confusion_matrix(Y_test, Y_pred))\n",
    "confusion_mat.columns = [c + ' predicted' for c in lm.classes_]\n",
    "confusion_mat.index = [c + ' true' for c in lm.classes_]\n",
    "\n",
    "print(confusion_mat)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for i in range(1,21):\n",
    "  knn = KNeighborsClassifier(i)\n",
    "  knn.fit(X_train,Y_train)\n",
    "  print(accuracy_score(Y_test,knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "Y_pred_train = lm.predict(X_train)\n",
    "Y_pred_test = lm.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "training_accuracy = accuracy_score(Y_train, Y_pred_train)\n",
    "testing_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "print(\"Training accuracy: %\", training_accuracy)\n",
    "print(\"Testing accuracy: %\", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature reduction\n",
    "coefficients = lm.coef_[0]\n",
    "n_possible_features = len(coefficients)\n",
    "n_features_used = sum(coefficients != 0)\n",
    "print(\"The original logistic regression model used %i out of a possible %i features\" % \n",
    "      (n_features_used, n_possible_features))\n",
    "\n",
    "l1m = linear_model.LogisticRegression(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001, C=c,\n",
    "    penalty='l1', solver='saga', random_state=42)\n",
    "\n",
    "lm_cv = linear_model.LogisticRegressionCV(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001,\n",
    "    solver='saga', random_state=42, refit=False,\n",
    "    Cs=3, penalty='l1'  #Specify the L1 penalty and set the number of Cs iterations to 5. \n",
    "    )\n",
    "\n",
    "lm_cv.fit(X_train, Y_train)\n",
    "print(\"Training accuracy:\", np.mean(Y_train==lm_cv.predict(X_train)))\n",
    "print(\"Testing accuracy:\", np.mean(Y_test==lm_cv.predict(X_test)))\n",
    "print(\"Number of non-zero coefficients in lasso model:\", sum(lm_cv.coef_[0]!=0))\n",
    "print(\"Lambda decided on by cross validation:\", 1/lm_cv.C_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (vpython)",
   "language": "python",
   "name": "python3.6-vpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
